# Prompt Optimization Proposal - Based on Research

**Date**: 2025-11-06
**Goal**: Optimize Phase 1 & 2 prompts for Haiku 4.5 based on latest research

---

## üî¨ Research Summary

### **Key Findings from 2024-2025 Studies**

1. **Format Efficiency (Frontiers AI 2025)**:
   - **JSON**: Highest accuracy (85% with Claude) for complex structures
   - **CSV/Prefix**: Best token & time efficiency for flat data
   - **Simpler formats** = faster processing across all models

2. **Anthropic's Official Guidelines**:
   - **Golden Rule**: "If a colleague with minimal context wouldn't understand, Claude won't"
   - **Be Direct**: Treat Claude like "brilliant but new employee" - needs explicit instructions
   - **Sequential Steps**: Use numbered lists, not verbose explanations
   - **Specify Output**: Explicitly state format preferences
   - **Precision > Verbosity**: Clarity beats over-explanation

3. **Haiku 4.5 Optimization (Anthropic)**:
   - Best for: **Well-structured problems**, lightweight extraction, formatted assembly
   - Achieves: **90% of Sonnet performance** at 4-5x speed
   - Optimized for: Clear instructions, clean structure, explicit formats
   - **NOT for**: Ambiguous prompts, complex reasoning, edge case synthesis

4. **Extraction Benchmarks**:
   - **Prompt-based KIE pipeline** (MDPI 2025): 95.5% precision with APE
   - **Key Success Factor**: Clean context + explicit output format
   - **Limitation**: LLMs may vary slightly between runs (~5% variance)

---

## üìã Current Prompts Analysis

### **Phase 1: Analysis Prompt** (Current: ~35 lines)

**Strengths**:
- ‚úÖ Clear objective (analyze and plan)
- ‚úÖ JSON output format specified
- ‚úÖ Compact business context

**Issues**:
- ‚ö†Ô∏è Unstructured context (long paragraph)
- ‚ö†Ô∏è Could use XML tags for better parsing
- ‚ö†Ô∏è Mixed instructions with context

**Verdict**: 7/10 - Works well but can be improved

---

### **Phase 2: Extraction Prompt** (Current: ~95 lines)

**Critical Issues**:
- ‚ùå **VERBOSE**: 5 PASSO sections with sub-bullets (lines 906-932)
- ‚ùå **REDUNDANT**: Multiple "CR√çTICO" warnings saying same thing
- ‚ùå **OVER-EXPLAINING**: Detailed schema descriptions not needed for Haiku
- ‚ùå **VIOLATES ANTHROPIC GUIDELINES**: "Brilliant but new employee" wouldn't need this much hand-holding
- ‚ùå **MIXED CONCERNS**: Instructions mixed with context mixed with warnings

**Verdict**: 3/10 - Too complex for Haiku, needs major simplification

---

## ‚ú® Optimized Prompts

### **PHASE 1: Analysis Prompt** (Optimized: ~30 lines)

**Key Changes**:
1. Use XML tags for structure (Anthropic guideline)
2. Numbered sequential steps (clarity)
3. Explicit output format requirements
4. Cleaner context separation

```xml
<task>
Analise este arquivo Excel e crie um plano de extra√ß√£o JSON.
</task>

<context>
<file_info>
- Nome do arquivo: "{filename}"
- Setor: Arquitetura (Brasil)
- Entidades esperadas: Contratos (projetos), Receb√≠veis (parcelas), Despesas
</file_info>

<business_context>
Arquitetos gerenciam projetos com contratos de honor√°rios, receb√≠veis parcelados (marcos ou mensalidades), e despesas operacionais (sal√°rios, software, marketing, espa√ßo).
</business_context>

<sheets_preview>
--- {sheetName1} ---
{first 10 rows CSV}

--- {sheetName2} ---
{first 10 rows CSV}
</sheets_preview>
</context>

<instructions>
Para cada planilha, identifique:
1. Tipo de entidade: "contracts" | "receivables" | "expenses" | "unknown"
2. N√∫mero aproximado de linhas de dados
3. Mapeamento de colunas para campos do schema
4. Refer√™ncias entre planilhas (ex: receivables ‚Üí project names)
</instructions>

<output_format>
Retorne APENAS JSON v√°lido neste formato exato:
{
  "sheets": [
    {
      "name": "string",
      "type": "contracts" | "receivables" | "expenses" | "unknown",
      "approximateRows": number,
      "columns": {"header1": "fieldName1", "header2": "fieldName2"},
      "notes": "string"
    }
  ],
  "projectNames": ["array of project names found"],
  "totalExpectedEntities": number
}
</output_format>
```

**Expected Impact**:
- ‚úÖ 20% faster processing (clearer structure)
- ‚úÖ More consistent output (explicit format)
- ‚úÖ Easier to maintain (separated concerns)

---

### **PHASE 2: Extraction Prompt** (Optimized: ~45 lines)

**Key Changes**:
1. **REMOVE**: All PASSO 1-5 verbose instructions (-25 lines)
2. **REMOVE**: Redundant CR√çTICO warnings (-3 lines)
3. **SIMPLIFY**: Schema to essential fields only
4. **USE**: XML structure for clarity
5. **DIRECT**: Clear numbered steps, not explanations

```xml
<task>
Extraia TODOS os dados desta planilha como JSON estruturado.
</task>

<context>
<file_info>
- Arquivo: "{filename}"
- Planilha: "{sheetName}"
- Tipo: {sheetType}
- Linhas esperadas: ~{approximateRows}
- Setor: Arquitetura (Brasil)
</file_info>

<analysis_plan>
- Colunas mapeadas: {columnsJSON}
- Projetos conhecidos: {projectNames}
- Notas: {notes}
</analysis_plan>

<data>
{full CSV data}
</data>
</context>

<instructions>
1. Extraia TODAS as {approximateRows} linhas - n√£o pule nenhuma
2. Uma entidade por linha (contract OU receivable OU expense)
3. Preencha campos usando o schema abaixo
4. Se campo OBRIGAT√ìRIO estiver vazio, pule essa linha
5. Campos OPCIONAIS vazios = null
</instructions>

<schema>
Contract (Contratos):
- clientName: string OBRIGAT√ìRIO
- projectName: string OBRIGAT√ìRIO
- totalValue: number OBRIGAT√ìRIO
- signedDate: ISO8601 OBRIGAT√ìRIO
- status: "active" | "completed" | "cancelled" OBRIGAT√ìRIO (default: "active")
- description: string | null
- category: string | null

Receivable (Receb√≠veis):
- amount: number OBRIGAT√ìRIO
- contractId: string | null (use projectName se dispon√≠vel)
- expectedDate: ISO8601 | null
- status: "pending" | "received" | "overdue" | null
- receivedDate: ISO8601 | null
- receivedAmount: number | null

Expense (Despesas):
- description: string OBRIGAT√ìRIO
- amount: number OBRIGAT√ìRIO
- category: string OBRIGAT√ìRIO (Alimenta√ß√£o | Transporte | Materiais | Servi√ßos | Escrit√≥rio | Marketing | Impostos | Sal√°rios | Outros)
- dueDate: ISO8601 | null
- status: "pending" | "paid" | "overdue" | "cancelled" | null
</schema>

<output_format>
Retorne APENAS JSON v√°lido:
{
  "contracts": [...],
  "receivables": [...],
  "expenses": [...]
}
</output_format>
```

**Expected Impact**:
- ‚úÖ **40-60% faster** processing (52% fewer tokens)
- ‚úÖ **Better for Haiku** (clear, structured, no over-explanation)
- ‚úÖ **Same accuracy** (all essential info preserved)
- ‚úÖ **Easier to debug** (separated concerns with XML)

---

## üìä Token & Cost Analysis

### **Current Implementation**

**Phase 1**:
- Input tokens: ~1,200 (context) + ~500 (preview) = ~1,700
- Thinking tokens: 2,000 (Haiku) or 5,000 (Sonnet)
- Output tokens: ~300 (JSON response)
- **Cost per file**: $0.002 (Haiku) | $0.0065 (Sonnet)

**Phase 2** (per sheet):
- Input tokens: ~3,500 (prompt) + ~2,000-10,000 (CSV data) = ~5,500-13,500
- Thinking tokens: 5,000 (Haiku) or 10,000 (Sonnet)
- Output tokens: ~2,000-5,000 (extracted JSON)
- **Cost per sheet**: $0.025 (Haiku) | $0.087 (Sonnet)

**Total (4-sheet file)**: ~$0.10 (Haiku) | $0.36 (Sonnet)

---

### **Optimized Implementation**

**Phase 1** (minimal change):
- Input tokens: ~1,000 (cleaner structure) = **-200 tokens**
- Same thinking/output
- **Cost per file**: $0.0018 (Haiku) | $0.006 (Sonnet)
- **Savings**: 10%

**Phase 2** (major optimization):
- Input tokens: ~1,800 (optimized prompt) + ~2,000-10,000 (CSV data) = ~3,800-11,800
- **Reduction**: -1,700 tokens per sheet (-48% prompt overhead)
- Thinking tokens: Same (5,000 Haiku | 10,000 Sonnet)
- Output tokens: Same (~2,000-5,000)
- **Cost per sheet**: $0.019 (Haiku) | $0.068 (Sonnet)
- **Savings**: 24%

**Total (4-sheet file)**: ~$0.076 (Haiku) | $0.272 (Sonnet)
**Overall Savings**: **24% cost reduction + 30-40% speed improvement**

---

## üéØ Expected Performance Improvements

### **Speed**

| Scenario | Current (Haiku) | Optimized (Haiku) | Improvement |
|----------|-----------------|-------------------|-------------|
| Small (10 entities) | 40s | 25-30s | **25-38%** |
| Medium (100 entities) | 70s | 45-55s | **29-36%** |
| Large (500 entities) | 120s | 70-85s | **29-42%** |

### **Accuracy**

- ‚úÖ **Same or better** - All essential information preserved
- ‚úÖ **More consistent** - Clearer structure reduces variance
- ‚úÖ **Fewer edge cases** - Direct instructions reduce confusion

### **Cost**

- ‚úÖ **24% reduction** on prompt overhead
- ‚úÖ **76% reduction** with prompt caching (Phase 3)
- ‚úÖ **Total**: ~$0.076/file (Haiku) vs $0.10/file (current)

---

## üöÄ Implementation Plan

### **Option A: Incremental (Safe)** ‚≠ê RECOMMENDED

**Week 1**: Optimize Phase 2 prompt only
1. Implement optimized Phase 2 prompt
2. Test with 15 diverse files
3. Compare accuracy vs current
4. Deploy if accuracy ‚â• 95%

**Week 2**: Optimize Phase 1 prompt
1. Implement optimized Phase 1 prompt
2. Test combined optimization
3. Measure full improvement
4. Deploy

**Timeline**: 2 weeks
**Risk**: LOW (incremental validation)
**Expected**: 30-40% speed improvement

---

### **Option B: All at Once (Fast)**

**Day 1-2**: Implement both optimizations
**Day 3-4**: Test with 15 diverse files
**Day 5**: Deploy if tests pass

**Timeline**: 1 week
**Risk**: MEDIUM (no fallback between phases)
**Expected**: 30-40% speed improvement

---

### **Option C: A/B Test (Data-Driven)**

**Phase 1**: Deploy optimized prompts to 10% of users
**Phase 2**: Monitor accuracy, speed, cost for 1 week
**Phase 3**: Gradual rollout (25% ‚Üí 50% ‚Üí 100%)

**Timeline**: 2-3 weeks
**Risk**: LOW (gradual rollout with monitoring)
**Expected**: 30-40% speed improvement + data-driven validation

---

## ‚úÖ Success Criteria

### **Speed**
- ‚úÖ Small files (10-50 entities): <30s (vs 40s baseline)
- ‚úÖ Medium files (100-200 entities): <60s (vs 90s baseline)
- ‚úÖ Large files (500+ entities): <90s (vs 150s baseline)

### **Accuracy**
- ‚úÖ Extraction accuracy ‚â• 95% (vs 100% baseline with one error)
- ‚úÖ No systematic errors or crashes
- ‚úÖ Edge case handling maintained or improved

### **Cost**
- ‚úÖ 24% prompt overhead reduction
- ‚úÖ Combined with caching: 76% total reduction
- ‚úÖ Target: <$0.08 per file average

---

## üìù Next Steps

1. **Review** this proposal with team
2. **Choose** implementation option (A, B, or C)
3. **Prepare** test file suite (15 diverse files)
4. **Implement** optimized prompts
5. **Test** accuracy and speed
6. **Deploy** if success criteria met
7. **Monitor** production metrics

---

## üîó Research References

1. Frontiers AI (2025): "Enhancing structured data generation with GPT-4o"
2. MDPI Electronics (2025): "Evaluation of Prompt Engineering on LLM Performance"
3. Anthropic Docs: "Prompt Engineering - Be Clear and Direct"
4. Anthropic: "Claude Haiku 4.5 Announcement"
5. Vanderbilt: "Prompt Patterns for Structured Data Extraction"

---

**Recommendation**: Start with **Option A (Incremental)** - optimize Phase 2 first (biggest impact), validate, then optimize Phase 1. This minimizes risk while maximizing learning.
